{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is an example for the training of the Efficientnetb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mode=\"dev\", percentage=0.3):\n",
    "    data = pd.read_csv('./train.csv')\n",
    "    if mode == \"prod\":\n",
    "        print(\"Prod mode used, all data used\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Dev mode used, percentage of the data used: {percentage}\")\n",
    "        return data.sample(frac=percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "device = get_device()\n",
    "\n",
    "image_size = 260\n",
    "target_size = 11\n",
    "target_cols = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                   'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n",
    "                   'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                   'Swan Ganz Catheter Present']\n",
    "data = get_data(mode=\"prod\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatasetTransformer\n",
    "\n",
    "This the class that will do the Data Augmentation and will transform the inputs into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTransformer(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, augmented=False, transform=None):\n",
    "        if transform is None:\n",
    "            if augmented:\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(image_size, image_size),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    ToTensorV2()\n",
    "                ])\n",
    "            else:\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(image_size, image_size),\n",
    "                    ToTensorV2()\n",
    "                ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.df = df\n",
    "        self.labels = self.df[target_cols].values\n",
    "        self.file_names = df['StudyInstanceUID'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.file_names[idx]\n",
    "        image_path = f'./train/{image_name}.jpg'\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image_t = self.transform(image=image)['image']\n",
    "        label = self.labels[idx]\n",
    "        data = { \n",
    "            \"image\": image_t.float(), \n",
    "            \"targets\": torch.tensor(self.labels[idx]).float()\n",
    "        }\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We use the library timm that holds multiple pre-trained models and create an interface that is the same for all different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        model = timm.create_model(model_name, pretrained=pretrained)\n",
    "            \n",
    "        n_features = model.classifier.in_features\n",
    "        \n",
    "        self.model = nn.Sequential(*list(model.children())[:-1])\n",
    "        self.drop_out = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(n_features, 11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.drop_out(x)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, loss_function, optimizer, weight_pos, weight_neg, device):\n",
    "    \"\"\"\n",
    "        It trains the model for one epoch\n",
    "    :param model: model we need to train\n",
    "    :param data_loader: Data loader (iterable)\n",
    "    :param loss_function: Loss Function\n",
    "    :param optimizer: Optimizer (e.g Adam)\n",
    "    :param device: \"cpu\" or \"cuda\"\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    total_number = 0.0\n",
    "    total_loss = 0.0\n",
    "    mean_auc = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        print(\"Training: batch \", i, end=\"\\r\")\n",
    "        image_input = data[\"image\"].to(device)\n",
    "        targets = data[\"targets\"].to(device)\n",
    "        outputs = model(image_input)\n",
    "        \n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        total_number += image_input.shape[0]\n",
    "        total_loss += image_input.shape[0] * loss.item()\n",
    "        mean_auc.append(mean_roc_auc(targets.detach().cpu(), outputs.detach().cpu()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss / total_number, np.average(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_roc_auc(targets, ouputs):\n",
    "    roc_auc = []\n",
    "    for k in range(11):\n",
    "        try:\n",
    "            roc_auc.append(metrics.roc_auc_score(targets[:, k], ouputs[:, k])) # it computes the AUC ROC metrics for each label and then averages it\n",
    "        except Exception as e:\n",
    "            roc_auc.append(0.5)\n",
    "            pass\n",
    "    return np.nanmean(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, loss_function, weight_pos, weight_neg, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_number = 0\n",
    "        total_loss, correctly_predicted = 0.0, 0.0\n",
    "        mean_auc = []\n",
    "        for i, data in enumerate(data_loader):\n",
    "            print(\"Test: batch \", i, end=\"\\r\")\n",
    "            image_input = data[\"image\"].to(device)\n",
    "            targets = data[\"targets\"].to(device)\n",
    "            outputs = model(image_input)\n",
    "            total_number += image_input.shape[0]\n",
    "            \n",
    "            total_loss += image_input.shape[0] * loss_function(outputs, targets).item()\n",
    "            mean_auc.append(mean_roc_auc(targets.cpu(), outputs.cpu()))\n",
    "    return total_loss / total_number, np.average(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_frac = 0.9 # We split the training data into 90% training and 10% validation\n",
    "train_data = data.sample(frac=train_validation_frac) \n",
    "validation_data = data.drop(train_data.index)\n",
    "\n",
    "train_dataset = DatasetTransformer(train_data, augmented=True)\n",
    "validation_dataset = DatasetTransformer(validation_data)\n",
    "train_dataset_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataset_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet(\"efficientnet_b2\", pretrained=True)\n",
    "model.to(device) # We send the model to the GPU (if available) to make the computation faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to visualize the architecture of the model\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters {pytorch_total_params}\")\n",
    "summary(model, (3, image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 0.0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.5, verbose=True, patience=3, mode='min', threshold=2*1e-2)\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphUpdater():\n",
    "    \"\"\"\n",
    "        Class that allows to save the loss and accuracy for different epoch and then compute the graph at the end of the training\n",
    "    \"\"\"\n",
    "    def __init__(self, type, name=None):\n",
    "        self.type = type\n",
    "        if name is None:\n",
    "            name = self.type + \"_loss_auc_\" + str(int(datetime.timestamp(datetime.now())))\n",
    "        self.filepath = os.path.join(\"./\", \"results\", \"epoch_model\")\n",
    "        self.name = name\n",
    "        self.loss = []\n",
    "        self.accuracy = []\n",
    "        self.epoch = []\n",
    "    \n",
    "    def update(self, loss, accuracy):\n",
    "        self.loss.append(loss)\n",
    "        self.accuracy.append(accuracy)\n",
    "        self.epoch.append(len(self.epoch))\n",
    "        df = pd.DataFrame(data={\"loss\": self.loss, \"accuracy\": self.accuracy, \"epoch\": self.epoch})\n",
    "        df.to_csv(os.path.join(self.filepath, self.name + \".csv\"), index_label=\"epoch\")\n",
    "        \n",
    "    def display(self):\n",
    "        df = pd.DataFrame(data={\"loss\": self.loss, \"accuracy\": self.accuracy, \"epoch\": self.epoch})\n",
    "        df.plot(x=\"epoch\", y=[\"loss\", \"accuracy\"], title=\"[\"+self.type + \"]\" + \" Loss and Accuracy per epoch\")\n",
    "        plt.show()\n",
    "        plt.savefig(os.path.join(self.filepath, self.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint:\n",
    "    \"\"\"\n",
    "        Class that allows to save the best model \n",
    "    \"\"\"\n",
    "    def __init__(self, model, filename=None, filepath=None):\n",
    "        self.min_loss = None\n",
    "        self.model = model\n",
    "\n",
    "        if filepath is None:\n",
    "            filepath = os.path.join(\"./\", \"results\", \"best_model\")\n",
    "\n",
    "        if filename is None:\n",
    "            filename = \"best_model_efficientnet_b7_v3.pt\"\n",
    "\n",
    "        self.filepath = os.path.join(filepath, filename)\n",
    "        \n",
    "    def update(self, loss):\n",
    "        if (self.min_loss is None) or (loss < self.min_loss):\n",
    "            print(f\"Saving a better model here: {self.filepath}\", end='\\n')\n",
    "            torch.save(self.model.state_dict(), self.filepath)\n",
    "            self.min_loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_updater = GraphUpdater(type=\"Train\")\n",
    "validation_updater = GraphUpdater(type=\"Validation\")\n",
    "model_checkpoint = ModelCheckpoint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training on {len(train_dataset)} images\")\n",
    "for t in range(epochs):\n",
    "        print(f'Epoch: {t}')\n",
    "\n",
    "        train_loss, train_auc = trainv2(model=model, data_loader=train_dataset_loader, loss_function=loss, optimizer=optimizer, weight_pos=freq_pos, weight_neg=freq_neg, device=device)\n",
    "        train_updater.update(**{\"loss\": train_loss, \"accuracy\": train_auc})\n",
    "        \n",
    "        print(f'Training step: Loss: {train_loss}, AUC: {train_auc}', end='\\n')\n",
    "        \n",
    "        val_loss, val_auc = testv2(model=model, data_loader=validation_dataset_loader,\n",
    "                                 loss_function=loss, weight_pos=freq_pos, weight_neg=freq_neg, device=device)\n",
    "        validation_updater.update(**{\"loss\": val_loss, \"accuracy\": val_auc})\n",
    "        \n",
    "        print(f'Validation step: Loss: {val_loss}, AUC: {val_auc}', end='\\n')\n",
    "        \n",
    "        model_checkpoint.update(loss=val_loss)\n",
    "        torch.save(model.state_dict(),f'./results/epoch_model/checkpoint_epoch_{t}.pt')\n",
    "        print('Model saved')\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "train_updater.display()\n",
    "validation_updater.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
